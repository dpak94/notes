---
type: "docs"
title: PySpark
draft: true
url: "/docs/db/pyspark/"
---

# PySpark

- Spark is one of the latest technologies being used to quickly and easily handle Big Data.
- It is an open source project on **Apache**.
- It is 100 times faster than Hadoop MapReduce.
- Spark does not store anything on the RAM unless any action is applied on the data (**Lazy Execution**)
- Apache Hadoop was performing batch-processing only and laced real-time processing feature.Spark does Batch and Real time processing
- Spark can load data directly from disk, memory and other data storage technologies such as Amazon S3, HDFS, Cassandra etc.

**Big Data Features**

- Volume - Size of the data
- Velocity - Speed at which data is gathered
- Variety - Different types of data
- Veracity - Trustworthiness of the data in terms of accuracy
- Value - Big Data can be turned into value

**HDFS** - Hadoop Distributed File System  
**YARN** - Yet Another Resource Negotiater

**RDDS - Resilient Distributed Dataset**

1. Stores intermediate results in distributed memory instead of stable storage(disk)
2. Lazy Evaluation - All trnasfomrations in PySpark are lazy, in that they do not compute their results right away.
3. Fault Tolerance
4. Data is safe to share across the proceses.
5. Partioning is the fundamental unit of parallelism in Spark RDD. Each partition is one logical division of data which is mutable.
6. Persistence - Users can state which RDD they will use and choose a storage strategy for them.
7. Coarse-grained Operations - Applies to all the elements in datasets thriugh maps or filter or group by operations

### Spark vs Hadoop Computing Engines

<table style="border-collapse:collapse;border-spacing:0" class="tg"><thead><tr><th style="background-color:#ffffff;border-color:#ffffff;border-style:solid;border-width:1px;color:#32cb00;font-family:Georgia, serif !important;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:middle;word-break:normal"><span style="font-weight:700;text-decoration:none">Map Reduce</span></th><th style="background-color:#ffffff;border-color:#ffffff;border-style:solid;border-width:1px;color:#32cb00;font-family:Georgia, serif !important;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:middle;word-break:normal"><span style="font-weight:700;text-decoration:none">Spark</span></th></tr></thead><tbody><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Computing   Framework Engine, open sourced by Apache</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Computing   Framework Engine, opensourced by Apache</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Map   Reduce is faster than traditional systems but it does not leverage the memory   of hadoop cluster to the maximum</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Spark   has been pproven to execute the batch processing jobs 10 to 100 times faster</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Disk   oriented completely. Higher latency.No caching support</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Spark   ensures lower latency computations by caching the partials results across its   memory of distributed hardware. Stores data in memory</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Cheaper   option available while comparing it in terms of cost</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Spark   requires lots of RAM to run in-memory. This increases the cluster, therbey   increasing the cost</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Writing   Map Reduce pipeline is complex and lengthy as it is purely Java</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Writing   Spark code is always easy and we can write in 4 languages</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Batch   processing</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Batch/iterative/Real   Time/Interactive Processing</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Fault   Tolerance and Highly Scalable and Cross Platform</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Fault   Tolerance and Highyly Scalable and Cross Platform</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Map   Reduce has been tested on 15000 nodes</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Spark   has been tested on 8000 nodes</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">It has   not inbuilt support to various things like SQL, ML & RT</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">It has   inbuilt support for RT, ML & SQL</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">It is   basic data processing engine</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">It is   data analytics enigne & is a choice for data scientists</span></td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Mapreduce   runs very well on commodity hardware</span></td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal"><span style="font-weight:400;text-decoration:none">Spark needs mid to high level hardware</span></td></tr></tbody></table>

### Pandas vs PySpark

<table style="border-collapse:collapse;border-spacing:0" class="tg"><thead><tr><th style="background-color:#ffffff;border-color:#ffffff;border-style:solid;border-width:1px;color:#32cb00;font-family:inherit;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:bottom;word-break:normal"><span style="font-weight:bold">PySpark API</span></th><th style="background-color:#ffffff;border-color:#ffffff;border-style:solid;border-width:1px;color:#009901;font-family:inherit;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:bottom;word-break:normal"><span style="font-weight:bold">Pandas API</span></th></tr></thead><tbody><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">Operations on PySpark DataFrame run parallel on diferent nodes in cluster</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Pandas will be using only cores of the CPU</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Operations are lazy in nature</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Results are obtained as soon as the operations are performed</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">In PySpark RDD, we cant change the DataFrame due to its immutable property, we need to transform it</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Pandas DF are not immutable in nature</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Supports less types of   operations</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Supports more operations than PySpark</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Complex operations are not   easier to perform</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Complex operations are easier to perform in Pandas</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">DataFrame Access is slower but   processing is faster</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Processing is slower but Pandas DF access is faster but   limited to available memory</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Setting up cluster is required</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">No need for a cluster</td></tr><tr><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Complicated</td><td style="background-color:#32cb00;border-color:#ffffff;border-style:solid;border-width:1px;color:#ffffff;font-family:inherit;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:bottom;word-break:normal">Simpler, flexible, more supporting libraries and easier to   implement</td></tr></tbody></table>

## Installation

`pip install pyspark`
